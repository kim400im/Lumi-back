from openai import OpenAI
import os

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from supabase import create_client, Client
from dotenv import load_dotenv

# ğŸ“¥ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Supabase ì„¤ì •
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase_client: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Embedding ëª¨ë¸
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

faiss_db = FAISS.load_local(
    "faiss_db",
    embedding_model,
    allow_dangerous_deserialization=True  # âœ… ë°˜ë“œì‹œ ëª…ì‹œ
)

# RunPod ì„¤ì •
RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")
RUNPOD_ENDPOINT_ID = os.getenv("RUNPOD_ENDPOINT_ID")
MODEL_NAME = os.getenv("RUNPOD_MODEL_NAME")

client = OpenAI(
    api_key=RUNPOD_API_KEY,
    base_url=f"https://api.runpod.ai/v2/{RUNPOD_ENDPOINT_ID}/openai/v1",
)

def format_messages(messages: list[dict]) -> list[dict]:
    return [{"role": m["role"], "content": m["content"]} for m in messages]

def run_llm_analysis(messages: list[dict], character_name: str, max_tokens: int = 512, temperature: float = 0.7) -> str:
    print("ğŸ” [LLM ë¶„ì„ ì‹œì‘]")
    
    # Llama 3.1 chat template ì •ì˜
    chat_template = """{% for message in messages %}
{{'<|start_header_id|>' + message['role'] + '<|end_header_id|>

' + message['content'] + '<|eot_id|>' }}
{% endfor %}
{% if add_generation_prompt %}
{{'<|start_header_id|>assistant<|end_header_id|>

'}}
{% endif %}"""

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            extra_body={
                "chat_template": chat_template  # âœ… chat template ì¶”ê°€
            }
        )
        
        print("âœ… RunPod ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
        if response and hasattr(response, 'choices') and len(response.choices) > 0:
            result = response.choices[0].message.content.strip()
            print(f"ğŸ’¬ ë¶„ì„ ê²°ê³¼: {result[:100]}...")
            return result
        else:
            print("âš ï¸ ì‘ë‹µì€ ìˆì§€ë§Œ ë‚´ìš©ì´ ì—†ìŒ")
            return "âŒ ì‘ë‹µ ë‚´ìš© ì—†ìŒ"
    
    except Exception as e:
        print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        return f"âŒ RunPod ìš”ì²­ ì‹¤íŒ¨: {str(e)}"


def find_similar_docs(query: str, k: int = 3) -> list[str]:
    results = faiss_db.similarity_search(query, k=k)
    docs = [doc.page_content for doc in results]
    
    # # âœ… ì—¬ê¸° ë¡œê·¸ ì¶”ê°€
    # print("ğŸ” FAISS ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ:")
    # for i, chunk in enumerate(docs):
    #     print(f"  [{i+1}] {chunk[:100]}{'...' if len(chunk) > 100 else ''}")
    
    # return docs
    print("ğŸ” FAISS ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ (ì „ì²´ ì¶œë ¥):")
    for i, chunk in enumerate(docs):
        print(f"\n===== [ë¬¸ì„œ {i+1}] =====")
        print(chunk)  # âœ… ì „ì²´ ë‚´ìš© ì¶œë ¥
    
    return docs